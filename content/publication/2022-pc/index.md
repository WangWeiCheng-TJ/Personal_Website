---
title: "An Opt-in Framework for Privacy Protection in Audio-Based Applications"
authors:
- admin
- Sander De Coninck
- Sam Leroux
- Pieter Simoens
date: "2022-10-01T00:00:00Z"
publishDate: "2022-10-01T00:00:00Z"
publication_types: [Journal article]
publication: "*IEEE Pervasive Computing, vol. 21, no. 4*"
publication_short: "*IEEE Pervasive Computing*"
doi: 10.1109/MPRV.2022.3210377

abstract: "Installing audio-based applications exposes users to the risk of the data processor extracting additional information beyond the task the user permitted. To solve these privacy concerns, we propose to integrate an on-edge data obfuscation between the audio sensor and the recognition algorithm. We introduce a novel privacy loss metric and use adversarial learning to train an obfuscator. Contrary to existing work, our technique does not require users to specify which sensitive attributes they want to protect (opt-out) but instead only provide permission for specific tasks (opt-in). Moreover, we do not require retraining of recognition algorithms, making the obfuscated data compatible with existing methods. We experimentally validate our approach on four voice datasets and show that we can protect several attributes of the speaker, including gender, identity, and emotional state with a minimal recognition accuracy degradation."
summary: "To address the privacy risks of audio applications extracting unauthorized user data, this work proposes an on-edge data obfuscator trained through adversarial learning, which uniquely operates on an opt-in permission model to protect sensitive speaker attributes while maintaining compatibility with existing recognition algorithms and incurring minimal accuracy degradation."

tags:
- Opt-in
- Audio Privacy
featured: true

url_pdf: 'https://ieeexplore.ieee.org/document/9925054'
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

image:
  caption: ''
  focal_point: 'Smart'
  preview_only: false

projects: []
slides: ""
---